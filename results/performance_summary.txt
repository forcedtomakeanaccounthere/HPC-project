================================================================
HPC Matrix-Vector Operations Performance Analysis Summary
================================================================

METHODOLOGY:
- Sequential C implementation with matrix-vector operations
- Compiled with GCC using different optimization levels
- Profiled with gprof for hotspot identification
- Timed execution with time command for performance comparison

OPTIMIZATION LEVELS TESTED:
1. Sequential (-O0 -pg): Baseline with profiling, no optimization
2. O2 Optimized (-O2 -pg): Moderate compiler optimizations
3. O3 Optimized (-O3 -pg): Aggressive compiler optimizations

EXPECTED RESULTS:
Based on algorithmic complexity analysis, the primary hotspots should be:

1. matrix_multiply() - O(n³) complexity
   - Expected: 70-80% of execution time
   - Parallelizable: YES (embarrassingly parallel)
   - Strategy: OpenMP + CUDA acceleration

2. matrix_vector_multiply() - O(n²) complexity  
   - Expected: 10-15% of execution time
   - Parallelizable: YES (independent rows)
   - Strategy: OpenMP parallel loops

3. data_preprocessing() - O(n) with expensive math operations
   - Expected: 5-10% of execution time
   - Parallelizable: YES (independent elements)
   - Strategy: OpenMP SIMD vectorization

ANALYSIS FILES GENERATED:
- sequential_profile.txt: Detailed gprof analysis of unoptimized version
- sequential_time.txt: Execution time and resource usage
- O2_optimized_profile.txt: Analysis with moderate optimization
- O3_optimized_profile.txt: Analysis with aggressive optimization
- performance_summary.txt: This summary document

NEXT STEPS:
1. Run: python3 analyze_hotspots.py results/sequential_profile.txt
2. Compare timing results across optimization levels
3. Implement OpenMP + CUDA parallelization based on hotspot analysis
4. Benchmark parallel versions against sequential baseline

PLATFORM RECOMMENDATION:
Based on the research paper "Enhancing Heterogeneous Computing Through OpenMP and GPU Graph":
- Primary: OpenMP for CPU task management and parallelization
- Secondary: CUDA for GPU acceleration of matrix operations
- Combined: Heterogeneous taskgraph approach following paper's methodology

================================================================
EXECUTION TIME COMPARISON:
================================================================

sequential version:
----------------------------------------
	User time (seconds): 2.15
	System time (seconds): 0.00
	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:02.21

O2_optimized version:
----------------------------------------
	User time (seconds): 0.56
	System time (seconds): 0.01
	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:00.62

O3_optimized version:
----------------------------------------
	User time (seconds): 0.56
	System time (seconds): 0.01
	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:00.62
